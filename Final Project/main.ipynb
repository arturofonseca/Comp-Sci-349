{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name: str) -> list[int]:\n",
    "    labels = []\n",
    "    attributes = []\n",
    "    with open(file_name) as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        index_of = {name: index for index, name in enumerate(next(csv_reader))}\n",
    "        # attributes = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day_of_week', 'campaign', 'previous', 'poutcome']\n",
    "        for line in csv_reader:\n",
    "            label = int(line[index_of['y']] == 'yes')\n",
    "            labels.append(label)\n",
    "            attributes.append(clean_example(index_of, line))\n",
    "    return labels, attributes\n",
    "\n",
    "def clean_example(index_of: dict[str:int], line: list[str]) -> list[int]:\n",
    "    jobs = [\"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\"]\n",
    "    marital = [\"divorced\",\"married\",\"single\",\"unknown\"]\n",
    "    education = [\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\"]\n",
    "    contact = [\"cellular\",\"telephone\"]\n",
    "    day_of_week = [\"mon\",\"tue\",\"wed\",\"thu\",\"fri\"]\n",
    "    poutcome = [\"failure\",\"nonexistent\",\"success\"]\n",
    "    binary = [\"no\", \"unknown\", \"yes\"]\n",
    "    age_min, age_max = 17, 98\n",
    "    age_numeric = (int(line[index_of['age']]) - age_min) / (age_max - age_min)\n",
    "    jobs_numeric = {job: index/(len(jobs)-1) for index, job in enumerate(jobs)}\n",
    "    marital_numeric = {status: index/(len(marital)-1) for index, status in enumerate(marital)}\n",
    "    education_numeric = {degree: index/(len(education)-1) for index, degree in enumerate(education)}\n",
    "    default_numeric = {status: index/(len(binary)-1) for index, status in enumerate(binary)}\n",
    "    housing_numeric = default_numeric\n",
    "    loan_numeric = default_numeric\n",
    "    contact_numeric = {method: index/(len(contact)-1) for index, method in enumerate(contact)}\n",
    "    day_of_week_numeric = {day: index/(len(day_of_week)-1) for index, day in enumerate(day_of_week)}\n",
    "    campaign_min, campaign_max = 1, 56\n",
    "    campaign_numeric = (int(line[index_of['campaign']]) - campaign_min) / (campaign_max - campaign_min)\n",
    "    previous_min, previous_max = 0, 7\n",
    "    previous_numeric = (int(line[index_of['previous']]) - previous_min) / (previous_max - previous_min)\n",
    "    poutcome_numeric = {outcome: index/(len(poutcome)-1) for index, outcome in enumerate(poutcome)}\n",
    "    return [age_numeric, jobs_numeric[line[index_of['job']]], marital_numeric[line[index_of['marital']]], education_numeric[line[index_of['education']]], default_numeric[line[index_of['default']]], housing_numeric[line[index_of['housing']]], loan_numeric[line[index_of['loan']]], contact_numeric[line[index_of['contact']]], day_of_week_numeric[line[index_of['day_of_week']]], campaign_numeric, previous_numeric, poutcome_numeric[line[index_of['poutcome']]]]\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear1 = nn.Linear(12, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.out = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def neural_network() -> None:\n",
    "    # Read data\n",
    "    train_labels, train_data = read_data('bank-train.csv')\n",
    "    valid_labels, valid_data = read_data('bank-valid.csv')\n",
    "    test_labels, test_data = read_data('bank-test.csv')\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(train_data), torch.tensor(train_labels))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    valid_dataset = TensorDataset(torch.tensor(valid_data), torch.tensor(valid_labels))\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Initialize model\n",
    "    ff = FeedForward()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(ff.parameters(), lr=0.01)\n",
    "\n",
    "    # Train the model\n",
    "    ff.train()\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for _ in range(20):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = ff(x)\n",
    "            loss_val = loss(y_hat, y)\n",
    "            train_loss += loss_val.item()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "        train_losses.append(train_loss)\n",
    "        for x, y in valid_loader:\n",
    "            y_hat = ff(x)\n",
    "            loss_val = loss(y_hat, y)\n",
    "            valid_loss += loss_val.item()\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    # Accuracy of test data\n",
    "    with torch.no_grad():\n",
    "        ff.eval()\n",
    "        predictions = ff(torch.tensor(test_data))\n",
    "        labels = [torch.argmax(prediction) for prediction in predictions]\n",
    "        correct_list = [int(label == prediction) for label, prediction in zip(test_labels, labels)]\n",
    "        accuracy = sum(correct_list) / len(correct_list)\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    # Plot losses\n",
    "    plt.plot([i for i in range(len(train_losses))], train_losses, label=\"Train Loss\")\n",
    "    plt.title(\"Train Loss vs. Epoch\")\n",
    "    plt.figure()\n",
    "    plt.plot([i for i in range(len(valid_losses))], valid_losses, label=\"Validation Loss\")\n",
    "    plt.title(\"Validation Loss vs. Epoch\")\n",
    "    matrix = metrics.confusion_matrix(test_labels, labels)\n",
    "    matrix_display = metrics.ConfusionMatrixDisplay(matrix)\n",
    "    matrix_display.plot()\n",
    "    plt.show()\n",
    "\n",
    "neural_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before pruning:\n",
      "Test accuracy: 85.99%\n",
      "Train accuracy: 92.98%\n",
      "\n",
      "Accuracy after pruning:\n",
      "Test accuracy: 89.24%\n",
      "Train accuracy: 89.80%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from math import log2\n",
    "from random import shuffle\n",
    "\n",
    "class Node:\n",
    "  def __init__(self, label:int=None, children:dict=None):\n",
    "    self.label = label\n",
    "    if children == None:\n",
    "      self.children = dict()\n",
    "    else:\n",
    "      self.children = children\n",
    "\n",
    "def are_all_same(examples: list[dict]) -> str|None:\n",
    "    \"\"\"Returns the class of a dataset if each example has the same class; otherwise, it returns nothing\n",
    "\n",
    "    Args:\n",
    "        examples (list[dict]): An array of examples. Each example is a dictionary of attribute:value pairs,\n",
    "    and the target class variable is a special attribute with the name \"Class\"\n",
    "\n",
    "    Returns:\n",
    "        str|None: Class or None\n",
    "    \"\"\"\n",
    "    first_class = examples[0]['y']\n",
    "    for example in examples:\n",
    "        if example['y'] != first_class:\n",
    "            return None\n",
    "    return first_class\n",
    "\n",
    "def most_common_class(examples: list[dict], target: str='y') -> str:\n",
    "    \"\"\"Returns the most common class of the dataset\n",
    "\n",
    "    Args:\n",
    "        examples (list[dict]): An array of examples. Each example is a dictionary of attribute:value pairs,\n",
    "    and the target class variable is a special attribute with the name \"Class\"\n",
    "        target (str, optional): Defaults to 'Class'.\n",
    "\n",
    "    Returns:\n",
    "        str: The most common class\n",
    "    \"\"\"\n",
    "    classes: Counter = Counter([example[target] for example in examples])\n",
    "    return classes.most_common(1)[0][0]\n",
    "\n",
    "def min_entropy(examples: list[dict], attributes: dict[str:set]) -> tuple[str,float]:\n",
    "  \"\"\"Returns a tuple of (attribute, entropy) for the attribute with the highest information gain\n",
    "\n",
    "  Args:\n",
    "      examples (list[dict]): An array of examples. Each example is a dictionary of attribute:value pairs,\n",
    "  and the target class variable is a special attribute with the name \"Class\"\n",
    "      attributes (dict[float:set]): A dictionary of attribute:values pairs\n",
    "\n",
    "  Returns:\n",
    "      tuple[str, float]: tuple of (attribute, info gain of attribute)\n",
    "  \"\"\"\n",
    "  def entopry(attribute: str) -> float:\n",
    "    value_to_count = {value:[] for value in attributes[attribute]}\n",
    "\n",
    "    # initializing probabilities of value\n",
    "    for example in examples:\n",
    "      value_to_count[example[attribute]].append(example)\n",
    "\n",
    "    # for each value of attribute, finding starting_entropy of data_value âŠ† data\n",
    "    starting_entropy = 0\n",
    "    for value_examples in value_to_count.values():\n",
    "      # value_examples = [{Class: 1, Weather: Cold}, {Class: 0, Weather: Cold}]\n",
    "      value_count = len(value_examples)\n",
    "      prob_val = value_count/len(examples)\n",
    "      class_to_count = {}\n",
    "      # initializing class count for each value\n",
    "      for ex in value_examples:\n",
    "        # ex = {Class: 1, Weather: Cold}\n",
    "        ex_class = ex['y']\n",
    "        if class_to_count.get(ex_class, False):\n",
    "          class_to_count[ex_class] += 1\n",
    "        else:\n",
    "          class_to_count[ex_class] = 1\n",
    "      \n",
    "      val_h = 0\n",
    "      for class_count in class_to_count.values():\n",
    "        prob_class_in_value = class_count/value_count\n",
    "        val_h += -1*(prob_class_in_value) * log2(prob_class_in_value)\n",
    "      starting_entropy += prob_val * val_h\n",
    "\n",
    "    return starting_entropy\n",
    "  \n",
    "  attr_entropy_list = []\n",
    "  for attribute in attributes:\n",
    "    attr_entropy_list.append((attribute, entopry(attribute)))\n",
    "  \n",
    "  return min(attr_entropy_list, key=lambda x: x[1])\n",
    "\n",
    "def read_data_tree(file_name: str) -> list[dict]:\n",
    "    data = []\n",
    "    with open(file_name) as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        care_about = {'y', 'age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'day_of_week', 'campaign', 'previous', 'poutcome'}\n",
    "        index_of = {name: index for index, name in enumerate(next(csv_reader))}\n",
    "        for line in csv_reader:\n",
    "            line = {name: line[index] for name, index in index_of.items() if name in care_about}\n",
    "            line['age'] = str(int(line['age']) - int(line['age']) % 20)\n",
    "            line['campaign'] = str(int(line['campaign']) - int(line['campaign']) % 10)\n",
    "            data.append(line)\n",
    "    return data\n",
    "\n",
    "def decision_tree(examples: list) -> Node:\n",
    "    attrs_vals = {\n",
    "        \"age\": {\"0\", \"20\", \"40\", \"60\", \"80\"},\n",
    "        \"job\": {\"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\"},\n",
    "        \"marital\": {\"divorced\",\"married\",\"single\",\"unknown\"},\n",
    "        \"education\": {\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\"},\n",
    "        \"default\": {\"no\", \"unknown\", \"yes\"},\n",
    "        \"housing\": {\"no\", \"unknown\", \"yes\"},\n",
    "        \"loan\": {\"no\", \"unknown\", \"yes\"},\n",
    "        \"contact\": {\"cellular\",\"telephone\"},\n",
    "        \"day_of_week\": {\"mon\",\"tue\",\"wed\",\"thu\",\"fri\"},\n",
    "        \"campaign\": {\"0\", \"10\", \"20\", \"30\", \"40\", \"50\"},\n",
    "        \"previous\": {\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"},\n",
    "        \"poutcome\": {\"failure\",\"nonexistent\",\"success\"}\n",
    "    }\n",
    "    def recurse(data: list=examples, attributes: list=attrs_vals) -> Node:\n",
    "        # Bases cases\n",
    "        # !None = all same\n",
    "        if are_all_same(data) != None:\n",
    "            return Node(are_all_same(data))\n",
    "        node = Node(most_common_class(data))\n",
    "        if not attributes:\n",
    "            return node\n",
    "    \n",
    "        # Recursive cases\n",
    "        best_attribute = min_entropy(data, attributes)[0] # [0] is the attribute name\n",
    "        node.label = best_attribute\n",
    "\n",
    "        # Attach a default node in case an attribute is missing\n",
    "        # node.children['unknown'] = most_common_class(data)\n",
    "\n",
    "        # attributes[best_attribute] is a set of all possible values for the best attribute\n",
    "        for value in attributes[best_attribute]:\n",
    "            value_data = [d for d in data if d[best_attribute] == value] # list[dict]\n",
    "            if not value_data:\n",
    "               value_node = Node(most_common_class(data))\n",
    "               node.children[value] = value_node\n",
    "               continue\n",
    "\n",
    "            value_attributes = {attribute:values.copy() for attribute, values in attributes.items() if attribute != best_attribute}\n",
    "            value_node = recurse(value_data, value_attributes)\n",
    "            node.children[value] = value_node\n",
    "        \n",
    "        return node\n",
    "\n",
    "    return recurse()\n",
    "\n",
    "def evaluate(tree: Node, example: dict) -> str:\n",
    "    attribute = tree.label\n",
    "    if not tree.children:\n",
    "        return attribute\n",
    "    value = example[attribute]\n",
    "    next_tree = tree.children[value]\n",
    "    if not next_tree:\n",
    "        return tree.children['unknown']\n",
    "    return evaluate(next_tree, example)\n",
    "\n",
    "def most_common_class_of_node(node: Node) -> str:\n",
    "  \"\"\"Returns the most common class a node returns\n",
    "\n",
    "  Args:\n",
    "      node (Node): A node\n",
    "\n",
    "  Returns:\n",
    "      str: A class\n",
    "  \"\"\"\n",
    "  class_to_count = {}\n",
    "\n",
    "  def recurse(tree: Node=node) -> None:\n",
    "    # base case \n",
    "    if not tree.children:\n",
    "      class_ = tree.label\n",
    "      if not class_to_count.get(class_, False):\n",
    "        class_to_count[class_] = 1\n",
    "      else:\n",
    "        class_to_count[class_] += 1\n",
    "      return\n",
    "    for attribute, subtree in tree.children.items():\n",
    "      if attribute != 'default':\n",
    "        recurse(subtree)\n",
    "\n",
    "  recurse()\n",
    "  \n",
    "  return max(class_to_count, key=lambda x: class_to_count[x])\n",
    "\n",
    "def prune(node: Node, examples: list[dict]) -> None:\n",
    "  \"\"\"Takes in a trained tree and a validation set of examples.  Prunes nodes in order\n",
    "  to improve accuracy on the validation data; the precise pruning strategy is up to you.\n",
    "\n",
    "  Args:\n",
    "      node (Node): a trained tree\n",
    "      examples (list[dict]): a validation set of examples\n",
    "  \"\"\"\n",
    "  # reduced error pruning\n",
    "  def recurse(tree: Node=node) -> None:\n",
    "    accuracy = 0\n",
    "    for example in examples:\n",
    "        label = example['y']\n",
    "        y_hat = evaluate(tree, example)\n",
    "        accuracy += int(label == y_hat)\n",
    "    accuracy = accuracy / len(examples)\n",
    "    for value, subtree in tree.children.items():\n",
    "      # base cases\n",
    "      if value == 'default':\n",
    "        continue\n",
    "      if not subtree.children:\n",
    "        continue\n",
    "\n",
    "      # change node to most common class\n",
    "      tree.children[value] = Node(most_common_class_of_node(subtree))\n",
    "      new_accuracy = 0\n",
    "      for example in examples:\n",
    "        label = example['y']\n",
    "        y_hat = evaluate(tree, example)\n",
    "        new_accuracy += int(label == y_hat)\n",
    "      new_accuracy = new_accuracy / len(examples)\n",
    "\n",
    "      # put node back if worse, then recurse on node\n",
    "      if new_accuracy < accuracy:\n",
    "        tree.children[value] = subtree\n",
    "        recurse(subtree)\n",
    "      # if we keep pruned node, continue to next child\n",
    "  recurse()\n",
    "\n",
    "# Read data\n",
    "data = read_data_tree('bank-train.csv')\n",
    "shuffle(data)\n",
    "size = int(0.9 * len(data))\n",
    "train_data = data[:size]\n",
    "test_data = data[size:]\n",
    "\n",
    "# Train the model\n",
    "tree = decision_tree(train_data)\n",
    "\n",
    "# Test before pruning\n",
    "print(\"Accuracy before pruning:\")\n",
    "correct = 0\n",
    "for example in test_data:\n",
    "    label = example['y']\n",
    "    y_hat = evaluate(tree, example)\n",
    "    correct += int(label == y_hat)\n",
    "accuracy = correct / len(test_data)\n",
    "print(f\"Test accuracy: {accuracy:.2%}\")\n",
    "correct = 0\n",
    "for example in train_data:\n",
    "    label = example['y']\n",
    "    y_hat = evaluate(tree, example)\n",
    "    correct += int(label == y_hat)\n",
    "accuracy = correct / len(train_data)\n",
    "print(f\"Train accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Test after pruning\n",
    "print(\"\\nAccuracy after pruning:\")\n",
    "prune(tree, test_data)\n",
    "correct = 0\n",
    "for example in test_data:\n",
    "    label = example['y']\n",
    "    y_hat = evaluate(tree, example)\n",
    "    correct += int(label == y_hat)\n",
    "accuracy = correct / len(test_data)\n",
    "print(f\"Test accuracy: {accuracy:.2%}\")\n",
    "correct = 0\n",
    "for example in train_data:\n",
    "    label = example['y']\n",
    "    y_hat = evaluate(tree, example)\n",
    "    correct += int(label == y_hat)\n",
    "accuracy = correct / len(train_data)\n",
    "print(f\"Train accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
